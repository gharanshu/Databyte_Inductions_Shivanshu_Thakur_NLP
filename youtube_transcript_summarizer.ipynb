{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ec4e7a-3a0e-4565-a5d4-8dd8ca073c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import transformers\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "272c8345-e91d-4ef7-9064-c665940c8dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.data.path.append('C:/Users/Sai/nltk_data')\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019b5798-bd25-4852-ae08-97761c8725c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!py -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac78371-5d50-45b2-a048-d4b45acc53ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def video_transcript(video_id):\n",
    "    text = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    return text\n",
    "get_video_transcript('aDG1T0kJnd4')'''\n",
    "def get_video_transcript(video_id):\n",
    "    return \" \".join([entry['text'] for entry in YouTubeTranscriptApi.get_transcript(video_id)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b1027e7-cc35-49a5-a99c-0495b29f1ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you. Thank you. So, my father used to always tell me something\n",
      "which I want to share with you, that why do you want to fit inside a glass slipper? You know, like we were told, like Cinderella\n",
      "did, why do you want to fit inside a glass slipper when you can shatter the glass ceiling? I want to tell you a little secret. I'm not very fond of this phrase, breaking\n",
      "the glass ceiling. Why does it annoy me? Because it takes the context of everything\n",
      "that I have done. All my achievements, all my ha\n"
     ]
    }
   ],
   "source": [
    "#we need to be able to get video id from the url\n",
    "#we use regex for this function\n",
    "def extract_id_from_url(url):\n",
    "    pattern = r'[?&]v=([^&]+)'\n",
    "    match = re.search(pattern, url)\n",
    "    return match.group(1)\n",
    "text = get_video_transcript(extract_id_from_url('https://www.youtube.com/watch?v=aDG1T0kJnd4'))\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d542465-10fb-41ff-a009-47b87b86e45a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thank you thank you so my father used to always tell me somethingwhich i want to share with you that why do you want to fit inside a glass slipper you know like we were told like cinderelladid why do you want to fit inside a glass slipper when you can shatter the glass ceiling i want to tell you a little secret im not very fond of this phrase breakingthe glass ceiling why does it annoy me because it takes the context of everythingthat i have done all my achievements all my hard work andputs it i\n"
     ]
    }
   ],
   "source": [
    "#text-preprocessing step1: removal of punctuation, lowercasing, removal of html tags, removal of emojis etc,\n",
    "exclude = string.punctuation\n",
    "'''def remove_html_tags(text):\n",
    "    html = re.compile('<*?>')\n",
    "    return pattern.sub(r'', text)\n",
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('','', exclude))\n",
    "def lower(text):\n",
    "    return text.str.lower()'''\n",
    "\n",
    "def preprocessing1(text):\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = text.translate(str.maketrans('','', exclude))\n",
    "    text = text.lower()\n",
    "    text = text.encode('utf-8', 'ignore').decode('utf-8')\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    return text\n",
    "cleaned_text = preprocessing1(text)\n",
    "print(cleaned_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79559d9-a11c-4087-9425-a76c95dae1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fafe34a-b498-4256-a331-bd0b4a07ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_words = [token.lemma_ for token in doc if not token.is_punct]\n",
    "    text = ' '.join(lemmatized_words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64bbb12b-de8c-4aaf-bd32-5badd16b87e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = lemmatize_text(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "064b289b-31e6-4a6f-8ffe-5bd84a6e10f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thank you thank you so my father use to always tell I somethingwhich I want to share with you that why do you want to fit inside a glass slipper you know like we be tell like cinderelladid why do you want to fit inside a glass slipper when you can shatter the glass ceiling I want to tell you a little secret I m not very fond of this phrase breakingthe glass ceiling why do it annoy I because it take the context of everythingthat I have do all my achievement all my hard work andput it into a box a'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e84f6eb-7148-4557-90cd-4abf8c08d736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-small and revision d769bba (https://huggingface.co/google-t5/t5-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sai\\OneDrive\\Desktop\\text summ final\\text_fin\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebf0bca428341cebc781d72a43b9956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''#text_vectorization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7fc85e-16c3-441c-9287-832104117520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use built in library to form extractive summarization \n",
    "'''from transformers import pipeline\n",
    "\n",
    "# Load the pre-trained summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model = \"t5-small\")\n",
    "\n",
    "# Define your long text (the cleaned and lemmatized text)\n",
    "long_text = cleaned_text[:500]\n",
    "\n",
    "# Summarize the text\n",
    "summary = summarizer(long_text, max_length=150, min_length=30, do_sample=False)\n",
    "\n",
    "# Print the summary\n",
    "print(summary[0]['summary_text'])'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75493815-bc85-4559-8d2e-a3ba6e097034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe93b7a-3192-4d36-9932-37d9d707d095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5b0c06-e38d-459f-99a8-a2d9ffa4c641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580b2ea-a61d-442f-a643-ed5054c6d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ac180-b5fb-44a9-8739-31e9218e73d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
